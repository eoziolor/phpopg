Oct 11, 2018
===
## Trimming and Aligning

* Still trying to figure out how to trim properly. The problem seems to be Nextera transposase sequence.
* SeqAnswers tells me that "CTGTCTCTTATA" works well to clean it up. Let's try.
    * [webpage](http://seqanswers.com/forums/showthread.php?t=49702)

* Using the following as a test script to see if it improves the quality and removes all needed adapter sequences

```
#!/bin/bash -l

#SBATCH -J combo_trimalign
#SBATCH --array=1-10
#SBATCH -e combo_trimalign%A-%a.o
#SBATCH -o combo_trimalign%A-%a.o
#SBATCH -N 1
#SBATCH -n 8
#SBATCH -t 01-00:00
#SBATCH --mem=8000

module load bio3

#Assigning number to be able to get into each folder separately

if (($SLURM_ARRAY_TASK_ID < 10))
then
	num=00$(echo $SLURM_ARRAY_TASK_ID)
elif (($SLURM_ARRAY_TASK_ID < 100))
then
	num=0$(echo $SLURM_ARRAY_TASK_ID)
else
	num=$(echo $SLURM_ARRAY_TASK_ID)
fi

echo $num

#Assigning new sample numbers with same amount of digits
if (($SLURM_ARRAY_TASK_ID < 10))
then
        sample=000$(echo $SLURM_ARRAY_TASK_ID)
elif (($SLURM_ARRAY_TASK_ID < 100))
then
        sample=00$(echo $SLURM_ARRAY_TASK_ID)
elif (($SLURM_ARRAY_TASK_ID <1000))
then
	sample=0$(echo $SLURM_ARRAY_TASK_ID)
else
        sample=$(echo $SLURM_ARRAY_TASK_ID)
fi


#Directory and file assignment for each file and program
my_dir=/home/eoziolor/phpopg/data/128.120.88.242/raw_data
fq1=$my_dir/AWPH*$num/*1.fq.gz
fq2=$my_dir/AWPH*$num/*2.fq.gz
my_bwa=/home/eoziolor/program/bwa-0.7.17/bwa
my_sbl=/home/eoziolor/program/samblaster/samblaster
my_sam=/home/eoziolor/program/samtools-1.9/samtools
my_out=/home/eoziolor/phpopg/data/align/
my_gen=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta
my_list=/home/eoziolor/phpopg/data/list/pop_samples.tsv

#others
pop=$(cat $my_list | grep $sample | cut -f 2)

#Code
paste <(zcat $fq1 | paste - - - -) \
      <(zcat $fq2 | paste - - - -) |\
tr '\t' '\n' |\
cutadapt -j 8 --interleaved -a CTGTCTCTTATA -A CTGTCTCTTATA -u 10 -U 10 -q 30 --trim-n --minimum-length 36 - | gzip > $my_out/AWPH.$sample.fq.gz
```
* Now using the fastqc script below to asses the quality:

```
#!/bin/bash

#SBATCH -J ph_fastqc
#SBATCH --array=1-10
#SBATCH -e ph_fastqc%A-%a.o
#SBATCH -o ph_fastqc%A-%a.o
#SBATCH -N 1
#SBATCH -n 1
#SBATCH -t 01:30:00
#SBATCH --mem=8000

module load bio3
fastqc --version

#folder
my_dir=/home/eoziolor/phpopg/data/align/
#my_out=/home/eoziolor/phpopg/data/align/
cd $my_dir

if (($SLURM_ARRAY_TASK_ID < 10))
then
	num=000$(echo $SLURM_ARRAY_TASK_ID)
elif (($SLURM_ARRAY_TASK_ID < 100))
then
	num=00$(echo $SLURM_ARRAY_TASK_ID)
else
	num=$(echo $SLURM_ARRAY_TASK_ID)
fi

echo $num

#code
fastqc AWPH.$num.fq.gz \
-o $my_dir
```

## Past quality

* Quality looks pretty good, so it is time that we go onto trimming and aligning altogether. Let's do it!!!

* used this to pad the list with zeros

```
my_list=/home/eoziolor/phpopg/data/list/pop_samples.tsv 

printf "%04d\n" $(cat $my_list | awk '{print $1}') | sed 's/0000/0001/' > zeros_samples_list.txt
```

* merged with list of sample pops as

```
cat pop_samples.tsv | awk '{print $2}' | paste zeros_samples_list.txt - > zeros_samples.tsv
```
* indexing genome

```
/home/eoziolor/program/bwa-0.7.17/bwa index phgenome_masked.fasta
/home/eoziolor/program/samtools-1.9/bin/samtools faidx phgenome_masked.fasta
```
* Let's give alignment a shot

```
#!/bin/bash -l

#SBATCH -J combo_trimalign
#SBATCH --array=1-10
#SBATCH -e combo_trimalign%A-%a.o
#SBATCH -o combo_trimalign%A-%a.o
#SBATCH -N 1
#SBATCH -n 8
#SBATCH -t 01-00:00
#SBATCH --mem=8000

module load bio3

#Assigning number to be able to get into each folder separately

if (($SLURM_ARRAY_TASK_ID < 10))
then
	num=00$(echo $SLURM_ARRAY_TASK_ID)
elif (($SLURM_ARRAY_TASK_ID < 100))
then
	num=0$(echo $SLURM_ARRAY_TASK_ID)
else
	num=$(echo $SLURM_ARRAY_TASK_ID)
fi

echo $num

#Assigning new sample numbers with same amount of digits
if (($SLURM_ARRAY_TASK_ID < 10))
then
        sample=000$(echo $SLURM_ARRAY_TASK_ID)
elif (($SLURM_ARRAY_TASK_ID < 100))
then
        sample=00$(echo $SLURM_ARRAY_TASK_ID)
elif (($SLURM_ARRAY_TASK_ID <1000))
then
	sample=0$(echo $SLURM_ARRAY_TASK_ID)
else
        sample=$(echo $SLURM_ARRAY_TASK_ID)
fi


#Directory and file assignment for each file and program
my_dir=/home/eoziolor/phpopg/data/128.120.88.242/raw_data
fq1=$my_dir/AWPH*$num/*1.fq.gz
fq2=$my_dir/AWPH*$num/*2.fq.gz
my_bwa=/home/eoziolor/program/bwa-0.7.17/bwa
my_sbl=/home/eoziolor/program/samblaster/samblaster
my_sam=/home/eoziolor/program/samtools-1.9/samtools
my_out=/home/eoziolor/phpopg/data/align/
my_gen=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta
my_list=/home/eoziolor/phpopg/data/list/zeros_samples.tsv

#others
pop=$(cat $my_list | grep $sample | cut -f 2)
rg=$(echo \@RG\\tID:$sample\\tPL:Illumina\\tPU:x\\tLB:combined\\tSM:$sample.$pop)
outroot=$sample\_$pop

#Code
paste <(zcat $fq1 | paste - - - -) \
      <(zcat $fq2 | paste - - - -) |\
tr '\t' '\n' |\
cutadapt -j 8 --interleaved -a CTGTCTCTTATA -A CTGTCTCTTATA -u 10 -U 10 -q 30 --trim-n --minimum-length 36 - |\
$my_bwa mem $my_gen -p -R $rg -t 2 - |\
$my_sam view -S -h -u - | \
$my_sam sort -T $my_out/$outroot > $my_out/$outroot
```

Oct. 12, 2018
===
# VERY IMPORTANT ABOUT ALIGNMENT SCRIPT

* this script produces two false positive files because of the crappy way that the folder names are named
    * I am missing folders 097 and 199, but the script still produces files with alignments in them because it draws from folders 1097 and 1199. I will delete these alignments.
    * For the future I have made sure that this does not happen by padding down the names of the alignment files with the correct amount of 0s (ex. 0097, 0199)
    * freaking novogene...

# Basic stats

* I will use samtools flagstat to get alignment statistics

```{bash}
#!/bin/bash -l

#SBATCH -J flagstat
#SBATCH -e flagstat-%j.o
#SBATCH -o flagstat-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH -t 01-00:00
#SBATCH --mem=60000
#SBATCH -p high

#files
my_dir=/home/eoziolor/phpopg/data/align
my_sam=/home/eoziolor/program/samtools-1.9/bin/samtools
my_out=/home/eoziolor/phpopg/data/align/stats.txt

#code
for file in $my_dir/*.bam; do
	$my_sam flagstat $file >> $my_out
done
```

* Created a file list for all bam files

```{bash}
cat zeros_samples.tsv | tr '\t' '_' | sed 's/^/\/home\/eoziolor\/phpopg\/data\/align\//' | sed 's/$/.bam/' > bam_list.txt
```

* Installing bamtools

```{bash}
git clone git://github.com/pezmaster31/bamtools.git
module load cmake
cd bamtools
mkdir build
cd build
cmake -DCMAKE_INSTALL_PREFIX=/home/eoziolor/program/bamtools ..
make
make DESTDIR=/home/eoziolor/program/bamtools install
```

* Merging files with bamtools

```{bash}
#!/bin/bash -l

#SBATCH -J mergebam
#SBATCH -e mergebam-%j.o
#SBATCH -o mergebam-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH -t 02-00:00
#SBATCH --mem=60000
#SBATCH -p high

#files
my_bam=/home/eoziolor/program/bamtools/build/src/toolkit/bamtools
my_merge=/home/eoziolor/phpopg/data/align/allmerge.bam
my_list=/home/eoziolor/phpopg/data/list/bam_list.txt

#code
$my_bam merge -list $my_list -out $my_merge
```

## Looking at mapping success rate and coverage

* Using samtools flagstat then grabbing mapped reads line

```{bash}
cat stats.txt | grep "mapped (" | awk '{OFS=" "}{print $1}' > mapped_reads.txt
#in folder with bam files
ls -1 | head -n -4 | tr '_' '\t' | sed 's/.bam//g' | paste - mapped_reads.txt > mapped_reads_ind.txt
```

* moved these in R and analyzed for coverage per population

## Loading in read coverage
```{r}
library(ggplot2)
mapped<-read.csv("~/phpopg/data/mapped_reads_ind.txt",header=F,sep='\t')
mapped<-na.omit(mapped)

#calculating coverage
mapped[,4]<-mapped[,3]*140/900000000

#histogram for overall coverage
hist(mapped[,4],breaks=100)

#converting ind to numeric
mapped[,1]<-as.numeric(mapped[,1])

#creating a vector of plate #
for(i in 1:20){
  for(j in 1:(dim(mapped)[1])){
    if(mapped[j,1]<=i*64&&mapped[j,1]>(i-1)*64){
    mapped[j,5]<-i
  }
  }
}

#naming columns
colnames(mapped)<-c("ind","pop","reads","cov","plate")

ggplot(mapped,
       aes(x=pop,y=cov,color=pop))+
  geom_violin(color="black")+
  geom_jitter()+
  theme_classic()

ggplot(mapped,
       aes(x=as.factor(plate),y=cov,color=plate))+
  geom_violin(color="black")+
  geom_jitter()+
  theme_classic()
```

Oct 17, 2018
===
# Doing per base coverage

```{bash}
#!/bin/bash -l

#SBATCH -J bamdepth
#SBATCH -e bamdepth-%j.o
#SBATCH -o bamdepth-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH -t 06-00:00
#SBATCH --mem=60000
#SBATCH -p high

module load bio3

#files
my_list=/home/eoziolor/phpopg/data/list/bam_list.txt
#my_stools=/home/eoziolor/program/samtools-1.9/bin/samtools
my_out=/home/eoziolor/phpopg/data/depth/coverage_allbases.txt.gz

#code
samtools depth \
-d 10000 \
-f $my_list | gzip > $my_out
```

Oct 21, 2018
===
## Depth threshold determination

* Grabbing random 10Mb depth region

```{bash}
#!/bin/bash -l

#SBATCH -J rand10Mb
#SBATCH -e rand10Mb-%j.o
#SBATCH -o rand10Mb-%j.o
#SBATCH -N 1
#SBATCH -n 8
#SBATCH -t 03-00:00
#SBATCH --mem=60000
#SBATCH -p high

module load bio3

#files
dir=/home/eoziolor/phpopg/data/depth

zcat $dir/coverage_allbases.txt.gz | \
sort -R | \
head -n 10000000 | \
gzip > $dir/cov_10Mbrand.txt.gz
```

## Plotting coverage distribution

* Downloading file
```{bash}
scp -P 2022 farm:/home/eoziolor/phpopg/data/depth/cov_10Mbrand.txt.gz ~/phpopg/data/depth/
```

* Observing distribution
```{r}
cov<-read.table("~/phpopg/data/depth/cov_10Mbrand.txt.gz",header=F)
names<-c("chrom","pos","cov")

hist(cov$cov,breaks=1000)

subw<-cov$cov<3000
hist(cov[subw,"cov"],breaks=1000)

summary(cov$cov)
summary(cov[subw,"cov"])
```

# Creating a genome file
```{bash}
awk -v OFS='\t' {'print $1,$2'} phgenome_masked.fasta.fai > phgenome_masked.fasta.genome
```

Oct 22, 2018
===

# Bimodal coverage distribution
* fist I use grep to figure out what line I need to stop reading the coverage file at to exclude any small scaffolds - scaffold 6281 and on

```{bash}
zcat coverage_allbases.txt.gz | awk '{print $1}' | grep -n "scaffold6281" | head
```

* I then reformat my script to only read up to that line and randomize coverage up to that line

```{bash}
#!/bin/bash -l

#SBATCH -J rand10Mb10k
#SBATCH -e rand10Mb10k-%j.o
#SBATCH -o rand10Mb10k-%j.o
#SBATCH -N 1
#SBATCH -n 8
#SBATCH -t 03-00:00
#SBATCH --mem=60000
#SBATCH -p high

module load bio3

#files
dir=/home/eoziolor/phpopg/data/depth

zcat $dir/coverage_allbases.txt.gz | \
head -n 529827386| \
sort -R | \
head -n 10000000 | \
gzip > $dir/cov_10Mb10k.txt.gz
```

* Creating a file without any bases represented >5000 times

```{bash}
#!/bin/bash -l

#SBATCH -J highcov
#SBATCH -e highcov-%j.o
#SBATCH -o highcov-%j.o
#SBATCH -N 1
#SBATCH -n 8
#SBATCH -t 03-00:00
#SBATCH --mem=60000
#SBATCH -p high

module load bio3
source ~/.bashrc

#files
my_cov=/home/eoziolor/phpopg/data/depth/coverage_allbases.txt.gz
my_out=/home/eoziolor/phpopg/data/depth/hicov.bed

zcat $my_cov | \
awk '{OFS="\t"}{s=$2-1}{print $1,s,$2,$3}' | \
awk '{OFS="\t"}{if($4>5000){print}}' | \
bedtools merge -i - -d 10 -c 4 -o count > $my_out
```
Oct 23, 2018
===

## Working on bimodal coverage

* Downloading document

```{bash}
scp -P 2022 farm:/home/eoziolor/phpopg/data/depth/cov_10Mb10k.txt.gz ~/phpopg/data/depth/
```

* Plotting high quality scaffold dist

```{r}
cov<-read.table("~/phpopg/data/depth/cov_10Mb10k.txt.gz",header=F)
names(cov)<-c("chrom","pos","cov")

hist(cov$cov,breaks=1000)

subw<-cov$cov<5000
hist(cov[subw,"cov"],breaks=1000)

summary(cov$cov)
summary(cov[subw,"cov"])
```

## How much did we throw out?

* Check how much of the genome you threw out

```{r}
hi<-read.table("~/phpopg/data/depth/hicov.bed",header=F)
print("percent thrown out")
(sum(hi[,4])/900000000)*100
```

Oct 25, 2018
===
* Install freebayes

```{bash}
cd /programs/
git clone --recursive git://github.com/ekg/freebayes.git
make
```

* Indexing merged bam file...all 970GB of it...

```{bash}
#!/bin/bash -l

#SBATCH -J bam_index
#SBATCH -e bam_index-%j.o
#SBATCH -o bam_index%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH -t 01-00:00
#SBATCH --mem=60000
#SBATCH -p high

my_stools=/home/eoziolor/program/samtools-1.9/samtools 
my_bam=/home/eoziolor/phpopg/data/align/allmerge.bam

$my_stools -@16 index $my_bam
```

Nov 27, 2018
===

## VCF calling

* Have been trying this script, but unfortunately that takes forever. 

```{bash}
#!/bin/bash -l

#SBATCH -J freebayes
#SBATCH --array=1-10000
#SBATCH -e freebayes%A-%a.o
#SBATCH -o freebayes%A-%a.o
#SBATCH -t 06-00:00
#SBATCH --cpus-per-task=1
#SBATCH --mem=8G
#SBATCH -p med
#SBATCH --no-requeue

cd /home/eoziolor/phpopg/data/varcall/scaffold/


#files
genome=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta
my_fai=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta.fai
mergebam=/home/eoziolor/phpopg/data/align/allmerge.bam
popsfile=/home/eoziolor/phpopg/data/list/zeros_samples.tsv
hicov=/home/eoziolor/phpopg/data/depth/hicov.bed
reg_file=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta.genome

#programs
my_freebayes=/home/eoziolor/program/freebayes/bin/freebayes
my_samtools=/home/eoziolor/program/samtools-1.9/samtools
my_bgz=/home/eoziolor/program/htslib/bgzip
my_bedtools=/home/eoziolor/program/bedtools2/bin/bedtools

#region to investigate

crap=$(echo $SLURM_ARRAY_TASK_ID)
scaf=$(sed "$crap q;d" $reg_file | cut -f1)
end=$(sed "$crap q;d" $reg_file | cut -f2)
region=$scaf:1-$end 

#directories and files

outdir=/home/eoziolor/phpopg/data/varcall/scaffold
outfile=$scaf.vcf.bgz

$my_samtools view -q 30 -f 2 -h -b  $mergebam $region | \
$my_bedtools intersect -v -a stdin -b $hicov | \
$my_freebayes -f $genome --populations $popsfile --stdin | \
$my_bgz > $outdir/$outfile

echo $outdir
echo $region
echo $outfile
echo $crap
echo $end
```

* In order to try and find the bottleneck here, I will try to run each portion of the samtools/bedtools/freebayes code separately and see what the limiting step is.
* Let's start with two scripts that will run just samtools and try to split it into multiple cores as well

```{bash}
#!/bin/bash -l

#SBATCH -J freebayes
#SBATCH --array=1-10
#SBATCH -e freebayes%A-%a.o
#SBATCH -o freebayes%A-%a.o
#SBATCH -t 06-00:00
#SBATCH --cpus-per-task=1
#SBATCH --mem=8G
#SBATCH -p med
#SBATCH --no-requeue

cd /home/eoziolor/phpopg/data/varcall/scaffold/


#files
genome=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta
my_fai=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta.fai
mergebam=/home/eoziolor/phpopg/data/align/allmerge.bam
popsfile=/home/eoziolor/phpopg/data/list/zeros_samples.tsv
hicov=/home/eoziolor/phpopg/data/depth/hicov.bed
reg_file=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta.genome

#programs
my_freebayes=/home/eoziolor/program/freebayes/bin/freebayes
my_samtools=/home/eoziolor/program/samtools-1.9/samtools
my_bgz=/home/eoziolor/program/htslib/bgzip
my_bedtools=/home/eoziolor/program/bedtools2/bin/bedtools

#region to investigate

crap=$(echo $SLURM_ARRAY_TASK_ID)
scaf=$(sed "$crap q;d" $reg_file | cut -f1)
end=$(sed "$crap q;d" $reg_file | cut -f2)
region=$scaf:1-$end 

#directories and files

outdir=/home/eoziolor/phpopg/data/varcall/scaffold
outfile=$scaf.vcf.bgz

#code to run
start=`date +%s`

$my_samtools view -q 30 -f 2 -h -b  $mergebam $region > $outdir/$scaf.bed
#$my_bedtools intersect -v -a stdin -b $hicov | \
#$my_freebayes -f $genome --populations $popsfile --stdin | \
#$my_bgz > $outdir/$outfile

end=`date +%s`
runtime=$((end-start))
echo "line took $((end-start)) seconds"

echo $outdir
echo $region
echo $outfile
echo $crap
echo $end
```

* I did the same with bedtools.
	* I don't think that either of those are the limiting reagent - both took less than 40 min to run for the largest scaffolds.
	* The issue must be with freebayes. I will systematically try to make it faster

* Things I am trying in order
	* Increasing the RAM available from 8GB to 16GB
		* that does work in making it a bit faster
	* Decreasing the number of alleles considered
		* adding --use-best-n-alleles 4 into the script in order to consider the top 4 allels


Nov 28, 2018
===

## Working on variant calling freebayes

* I have decided to call on scaffolds smaller than 500000 since those will call in time. for the rest of them I will write a different script that breaks each scaffold into 10-15 chunks and that should be fine for now.

* Small scaffold calling script

```{bash}
#!/bin/bash -l

#SBATCH -J freebayes
#SBATCH --array=300-10000
#SBATCH -e freebayes%A-%a.o
#SBATCH -o freebayes%A-%a.o
#SBATCH -t 06-00:00
#SBATCH --cpus-per-task=1
#SBATCH --mem=8G
#SBATCH -p med
#SBATCH --no-requeue

cd /home/eoziolor/phpopg/data/varcall/scaffold/

#files
genome=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta
my_fai=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta.fai
mergebam=/home/eoziolor/phpopg/data/align/allmerge.bam
popsfile=/home/eoziolor/phpopg/data/list/zeros_samples.tsv
hicov=/home/eoziolor/phpopg/data/depth/hicov.bed
reg_file=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta.genome

#programs
my_freebayes=/home/eoziolor/program/freebayes/bin/freebayes
my_samtools=/home/eoziolor/program/samtools-1.9/samtools
my_bgz=/home/eoziolor/program/htslib/bgzip
my_bedtools=/home/eoziolor/program/bedtools2/bin/bedtools

#region to investigate

crap=$(echo $SLURM_ARRAY_TASK_ID)
scaf=$(sed "$crap q;d" $reg_file | cut -f1)
end=$(sed "$crap q;d" $reg_file | cut -f2)
region=$scaf:1-$end 

#directories and files

outdir=/home/eoziolor/phpopg/data/varcall/scaffold
outfile=$scaf.vcf.bgz

$my_samtools view -q 30 -f 2 -h -b  $mergebam $region | \
$my_bedtools intersect -v -a stdin -b $hicov | \
$my_freebayes -f $genome --populations --use-best-n-alleles 4 $popsfile --stdin | \
$my_bgz > $outdir/$outfile

echo $outdir
echo $region
echo $outfile
echo $crap
echo $end
```


